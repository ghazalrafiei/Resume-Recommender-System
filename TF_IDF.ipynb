{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF-IDF.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1_9kiZMNpwFeGa-ldr1_YAUE3Z6wWSzCa",
      "authorship_tag": "ABX9TyPUrc+eGYMJHf5TTtYTPgNE",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ghazalrafiei/Resume-Recommender-System/blob/main/TF_IDF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfKcZY6es0TN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b671834d-99b4-49c4-ee0e-8cbe1fcabd9a"
      },
      "source": [
        "!pip install parsivar\n",
        "import re\n",
        "from parsivar import Normalizer,Tokenizer "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: parsivar in /usr/local/lib/python3.7/dist-packages (0.2.3)\n",
            "Requirement already satisfied: nltk==3.4.5 in /usr/local/lib/python3.7/dist-packages (from parsivar) (3.4.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.4.5->parsivar) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1D6co7N6oxrY"
      },
      "source": [
        "# import hazm\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMbpFsb2dRdO"
      },
      "source": [
        "  _normalizer = Normalizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmFvT3DntwZU"
      },
      "source": [
        "stop_words = set()\n",
        "def loads_stops():\n",
        "    h = Normalizer()\n",
        "    with open('/content/drive/MyDrive/resume/fa_stopwords.txt','r+') as s:\n",
        "        for w in s.readlines():\n",
        "            w = w.rstrip().replace('\\u200c',' ')\n",
        "            w = h.normalize(w)\n",
        "            stop_words.add(w)\n",
        "loads_stops()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BN5FDmYWOLy5"
      },
      "source": [
        "syn_df =  pd.read_csv('/content/drive/MyDrive/resume/synonyms.csv')\n",
        "eng_to_fa = {}\n",
        "for i in range(len(syn_df)):\n",
        "  eng_to_fa[syn_df['eng'][i]] = syn_df['fa'][i]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azA19YCT_KWH"
      },
      "source": [
        "def normaz(t):\n",
        "  _normalizer = Normalizer()\n",
        "  return _normalizer.normalize(t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwW4VhNVsjNF"
      },
      "source": [
        "def tokenizePersianText(text):\n",
        "  x = normaz(text)\n",
        "  x = x.replace('\\u200c',' ')\n",
        "  x = x.replace('\\u202a',' ')\n",
        "  x = x.replace('\\u202c',' ')\n",
        "  x = x.replace('\\u202b',' ')\n",
        "  x = x.replace('\\u202c',' ')\n",
        "\n",
        "  # ^((\\\\u202a)|(\\\\u202c)|(\\\\x0c)|(\\\\uf0b7)|\\\\ue812|\\\\u200c)\n",
        "  tz = Tokenizer()\n",
        "  tokens = tz.tokenize_words(x)\n",
        "  # s = SpellCheck()\n",
        "  # tokens = [s.spell_corrector(w) for w in text]\n",
        "\n",
        "  tokens = [w for w in tokens if not w in stop_words if len(w)>3 and w!='C']\n",
        "  for t in tokens:\n",
        "    if re.match(r'[a-zA-Z]',t):\n",
        "      if t.lower() in eng_to_fa.keys():\n",
        "        tokens.remove(t)\n",
        "        tokens.append(eng_to_fa[t.lower()])\n",
        "  return tokens\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBRc6Vfbg15H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39f23aba-b63f-4483-c258-667cf49981bf"
      },
      "source": [
        "description = ''\n",
        "with open('/content/drive/MyDrive/resume/desciption.txt') as f:\n",
        "  for r in f.readlines():\n",
        "    description += ' '+(r.rstrip())\n",
        "description = tokenizePersianText(description)\n",
        "print(description)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['دسته', 'شغلی', 'برنامه', 'نویسی', 'تهران', 'تهران', 'شغلی', 'شرکت', 'همپا', 'برنامه', 'نویس', 'Front', 'مسلط', 'React', 'بپیوندد', 'برنامه', 'نویس', 'مسئولیت', 'ساخت', 'اپلیکشن', 'Front', 'React', 'نوشتن', 'تمیز', 'نوشتن', 'HTML', 'تمیز', 'استانداردهای', 'Best', 'practice', 'نوشتن', 'Cross', 'browser', 'compatible', 'نوشتن', 'اپلیکیشن', 'Responsive', 'RESTfull', 'APIs', 'نیازمندی', 'نسخه', 'استاندارد', 'ECMAScript', 'تجربه', 'React', 'فریم', 'Node', 'Express', 'HTML5', 'CSS3', 'Bootstrap', 'Sass', 'Less', 'ارتباط', 'طراح', 'پیاده', 'تکنولوژی', 'برنامه', 'نویسی', 'نوشتن', 'ماهیانه', 'امکان', 'سهام', 'امکان', 'ارتقای', 'شغلی', 'مدیریت', 'معرفی', 'شرکت', 'همپا', 'مسیرهای', 'شهری', 'افراد', 'مشابهی', 'زمان', 'یکسان', 'اپلیکیشن', 'همپا', 'امکان', 'فراهم', 'صاحبان', 'خودرو', 'صندلی', 'خالی', 'خودروی', 'افراد', 'بدین', 'هزینه', 'درصد', 'کاهش', 'کارپولینگ', 'همسفری', 'دنیا', 'تاثیر', 'کاهش', 'خودروهای', 'سرنشین', 'قرار', 'نیاز', 'Front', 'React', 'HTML', 'Responsive', 'Restfull', 'فناوری', 'اطلاعات', 'ارتباطات', 'فناوری', 'اطلاعات', 'علوم', 'کامپیوتر', 'کامپیوتر', 'مهندسی', 'کامپیوتر', 'اپلیکیشن', 'جاواسکریپت']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdIOJvmCuwZ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c8ffc1a-ee9c-49a7-9dfa-1ff257acb4dc"
      },
      "source": [
        "import re\n",
        "resumes = {}\n",
        "emails = {}\n",
        "numbers = {}\n",
        "phones = {}\n",
        "urls = {}\n",
        "educations = {}\n",
        "university_experience = {}\n",
        "enterprise_experience = {}\n",
        "  \n",
        "university_experience = {}\n",
        "for i in range(1,35):\n",
        "  resume = ''\n",
        "  emails[i] = []\n",
        "  phones[i] = []\n",
        "  urls[i] = []\n",
        "  numbers[i] = []\n",
        "  educations[i] = []\n",
        "  university_experience[i] = []\n",
        "  enterprise_experience[i] = []\n",
        "  \n",
        "  with open(f'/content/drive/MyDrive/resume/resume{i}.txt') as f:\n",
        "    for lines in f.readlines():\n",
        "      line = lines.replace('\\n',' ')\n",
        "      emails[i]+=re.findall(r'[0-9a-zA-Z\\.-]+@[a-zA-Z\\.-]+',line)\n",
        "      line = re.sub(r'[0-9a-zA-Z\\.-]+@[a-zA-Z\\.-]+',' ',line)\n",
        "\n",
        "      # phones[i]+=re.findall(r'[\\+98|0]?9\\d{9}',line)\n",
        "      # re.sub(r'[\\+98|0]?9\\d{9}',' ',line)\n",
        "\n",
        "      # phones[i]+=re.findall(r'\\+\\u06F9\\u06F8|\\u06F90]?\\u06F9{\\u06F0-\\u06F9}{\\u06F9}',line)\n",
        "      # re.sub(r'\\+\\u06F9\\u06F8|\\u06F90]?\\u06F9{\\u06F0-\\u06F9}{\\u06F9}',' ',line)\n",
        "\n",
        "      numbers[i]+=re.findall(r'(\\d+|[\\u06F0-\\u06F9]+)',line)\n",
        "      line = re.sub(r'(\\d+|[\\u06F0-\\u06F9]+)',' ',line)\n",
        "\n",
        "      urls[i]+=re.findall(r'([https?:\\/\\/]?[www\\.]?[a-z0-9A-Z\\u06F0-\\u06F9]+\\.[a-z]+[\\/[a-z0-9]]?)',line)\n",
        "      line = re.sub(r'([https?:\\/\\/]?[www\\.]?[a-z0-9A-Z\\u06F0-\\u06F9]+\\.[a-z]+[\\/[a-z0-9]]?)',' ',line)\n",
        "      \n",
        "      linen = _normalizer.normalize(line)\n",
        "      educations[i]+=re.findall(r'(لیسانس|کارشناسی ارشد|کارشناسی|فوق لیسانس|دکترا|دیپلم|bachelor|diploma|master|bs|b\\.s|m\\.s|phd)',linen)\n",
        "      linen = re.sub(r'(لیسانس|کارشناسی ارشد|کارشناسی|فوق لیسانس|دکترا|دیپلم|bachelor|diploma|master|bs|b\\.s|m\\.s|phd)',' ',linen)\n",
        "        # print(linen)\n",
        "\n",
        "      if line.find('دانشگاه') != -1 or line.lower().find('university') != -1:\n",
        "        # print(line)\n",
        "        university_experience[i].append(linen)\n",
        "\n",
        "      if line.find('شرکت')!= -1 or line.find('کارخانه')!=-1:\n",
        "        # print(line)\n",
        "        enterprise_experience[i].append(_normalizer.normalize(line.replace('\\n',' ')))\n",
        "\n",
        "      resume += ' '+line.rstrip()\n",
        "  \n",
        "  res_tokens = tokenizePersianText(resume)\n",
        "  resumes[i] = res_tokens\n",
        "\n",
        "metadata = pd.DataFrame(index=range(1,35))\n",
        "metadata['email'] = emails.values()\n",
        "metadata['phone'] = phones.values()\n",
        "metadata['education'] = educations.values()\n",
        "metadata['university'] = university_experience.values()\n",
        "metadata['url'] = urls.values()\n",
        "metadata['enterprise'] = enterprise_experience.values()\n",
        "metadata['numbers'] = numbers.values()\n",
        "# metadata\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lH_vKLNK-eMS",
        "outputId": "43f76be7-af05-4f18-a675-f026c558bcf8"
      },
      "source": [
        "len(resumes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b67-ALJ4z9Oo"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def cosine_sim(text1, text2):\n",
        "    vectorizer = TfidfVectorizer(tokenizer=tokenizePersianText)\n",
        "\n",
        "    tfidf = vectorizer.fit_transform([text1, text2])\n",
        "    return ((tfidf * tfidf.T).A)[0,1]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlQAcPCv6UXV"
      },
      "source": [
        "similarities = {}\n",
        "i = 1\n",
        "for r in resumes.values():\n",
        "  if r:\n",
        "    similarities[i] = cosine_sim(description.__str__(), resumes[i].__str__())\n",
        "    i += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2o7BIxeDwPa"
      },
      "source": [
        "similarities\n",
        "resumes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcuC4EbSzt59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4e5ea3b4-ac48-453e-cced-ac7205db38e0"
      },
      "source": [
        "ranking = sorted(similarities.items(), key=lambda x: x[1], reverse=True)\n",
        "result = pd.DataFrame()\n",
        "result['number'] = [r[0] for r in ranking]\n",
        "result['tf-idf score'] = [r[1] for r in ranking]\n",
        "result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>number</th>\n",
              "      <th>tf-idf score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15</td>\n",
              "      <td>0.180145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14</td>\n",
              "      <td>0.176534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10</td>\n",
              "      <td>0.175945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>0.134028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>18</td>\n",
              "      <td>0.130825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>0.125364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>5</td>\n",
              "      <td>0.104131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>6</td>\n",
              "      <td>0.098177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>16</td>\n",
              "      <td>0.093133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>28</td>\n",
              "      <td>0.091855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>12</td>\n",
              "      <td>0.091219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>20</td>\n",
              "      <td>0.085963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>4</td>\n",
              "      <td>0.084412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>27</td>\n",
              "      <td>0.070649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>22</td>\n",
              "      <td>0.064661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>33</td>\n",
              "      <td>0.063894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2</td>\n",
              "      <td>0.059919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>29</td>\n",
              "      <td>0.058699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>8</td>\n",
              "      <td>0.046900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>31</td>\n",
              "      <td>0.044906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>25</td>\n",
              "      <td>0.033839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>30</td>\n",
              "      <td>0.029079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>19</td>\n",
              "      <td>0.027678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>3</td>\n",
              "      <td>0.024006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>26</td>\n",
              "      <td>0.020925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>21</td>\n",
              "      <td>0.020906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>24</td>\n",
              "      <td>0.020603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>11</td>\n",
              "      <td>0.016960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>32</td>\n",
              "      <td>0.014520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>23</td>\n",
              "      <td>0.006416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>7</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>13</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>17</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>34</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    number  tf-idf score\n",
              "0       15      0.180145\n",
              "1       14      0.176534\n",
              "2       10      0.175945\n",
              "3        9      0.134028\n",
              "4       18      0.130825\n",
              "5        1      0.125364\n",
              "6        5      0.104131\n",
              "7        6      0.098177\n",
              "8       16      0.093133\n",
              "9       28      0.091855\n",
              "10      12      0.091219\n",
              "11      20      0.085963\n",
              "12       4      0.084412\n",
              "13      27      0.070649\n",
              "14      22      0.064661\n",
              "15      33      0.063894\n",
              "16       2      0.059919\n",
              "17      29      0.058699\n",
              "18       8      0.046900\n",
              "19      31      0.044906\n",
              "20      25      0.033839\n",
              "21      30      0.029079\n",
              "22      19      0.027678\n",
              "23       3      0.024006\n",
              "24      26      0.020925\n",
              "25      21      0.020906\n",
              "26      24      0.020603\n",
              "27      11      0.016960\n",
              "28      32      0.014520\n",
              "29      23      0.006416\n",
              "30       7      0.000000\n",
              "31      13      0.000000\n",
              "32      17      0.000000\n",
              "33      34      0.000000"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    }
  ]
}